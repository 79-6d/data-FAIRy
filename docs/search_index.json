[
["index.html", "Data FAIRy About How to build this book locally", " Data FAIRy Anton Van de Putte, Yi-Ming Gan, Maxime Sweetlove 2021-06-03 About This document serves to guide researchers who wish to manage the biological data from their scientific expedition Issues or suggestions about the content can be raised through the issue tracker (GitHub account required). How to build this book locally This material has been written using bookdown and R. The dependencies of this project is managed using renv. To build the book locally, clone the repo. If dependencies are not automatically installed by renv when you open data-fairy.Rproj, try the following command. renv::restore() then run the following lines to build the book: setwd(here()) # set working directory to project root directory bookdown::render_book(&quot;index.Rmd&quot;) And view it with: browseURL(&quot;docs/index.html&quot;) "],
["introduction.html", "Chapter 1 Introduction", " Chapter 1 Introduction "],
["organization.html", "Chapter 2 Organization 2.1 Project structure 2.2 Organizational tips 2.3 Naming files", " Chapter 2 Organization Good file organization and naming is a mighty weapon against chaos. Informative file name and location tells you what it is, why it exists and its relationship with other things. The more self explanatory it can be, the better! README’s are great, but don’t document something that is self-documenting by definition. 2.1 Project structure Good project structure ├── README.md &lt;- The top-level README. ├── data │ ├── external &lt;- Data from third party sources. │ ├── interim &lt;- Intermediate data that has been transformed. │ ├── processed &lt;- The final, canonical data sets for modeling. │ └── raw &lt;- The original, immutable data dump. │ ├── references &lt;- Data dictionaries, manuals, and all other explanatory materials. │ ├── src &lt;- Source code for use in this project. │ ├── data &lt;- Scripts to download or generate data. │ │ └── make_dataset.R │ │ │ ├── clean &lt;- Scripts to clean data. │ │ └── clean_dataset.R │ │ │ └── visualization &lt;- Scripts to create exploratory and results oriented visualizations │ └── visualize.R └── reports &lt;- Generated QC reports. └── figures &lt;- Generated graphics and figures to be used in reporting. Adapted from Python’s version from Cookiecutter Data Science A good project structure encourages practice that make it easier to come back to old work and make the code easily reproducible. 2.2 Organizational tips A couple of tips from Jenny Bryan’s organization slides which worth to be mentioned: A quarantine directory Revoke write permission to raw data files A prose directory File organization reflects input vs outputs and the information flow 2.2.1 A quarantine directory If your collaborator send you data with space-containing file names, data in spreadsheet etc that do not fits your standard naming system and practice, you can place those files in a quarantine directory. The renamed or exported plain text files can be move to your data directory. Record what you did in a README or comments in your code to remind yourself about the file’s source, if it is from the outside world in a state that is not ready for your programmatic analysis. 2.2.2 Revoke write permission to raw data files So that it will not be accidentally edited by you or someone else. 2.2.3 A prose directory Sometimes you need a folder to keep key emails, internal documentation, explanations, random documents received. Similar to the quarantine directory, the prose directory can be used to park these things without having to keep the same standard for file names and open formats. 2.2.4 File organization should reflect input vs outputs and the information flow TODO add a figure 2.3 Naming files Jenny Bryan also has good tips in naming files summarized below. Good file names are: machine readable human readable orderable Good names 2021-05-20_antarctic-penguins.txt 001-248231_myctophidae-gill.jpg southern-ocean-jellyfish.docx Bad names 1.txt thesis final_Final_FINAL.docx nJ7UyiE*.txt ça va.txt 2.3.1 Machine readable Regular expression and globbing friendly Avoid: special characters spaces punctuation accented characters case sensitivity Use: delimiters File names follow the pattern: &lt;date&gt;_&lt;cruise-number&gt;_&lt;location&gt;.pdf _ underscore delimits units of metadata - hyphen delimits words for readability ~/Desktop/projects/01_cruise-reports ᐅ ls 2018-12-15_PS117_cape-town.pdf 2019-02-09_PS118_punta-arenas.pdf 2019-04-13_PS119_punta-arenas.pdf 2020-06-04_PS122-4_arctic-ocean.pdf 2020-08-12_PS122-5_arctic-ocean.pdf Using globbing/regular expression to narrow file listing: ~/Desktop/projects/01_cruise-reports ᐅ ls *arctic* 2020-06-04_PS122-4_arctic-ocean.pdf 2020-08-12_PS122-5_arctic-ocean.pdf 2.3.2 Human readable Names that tells you about the file content. Utilize the slug concept from semantic URLs. 2019-01-24_gis_vector.pdf 2019-02-12_gis_maps.pdf 2019-03-16_r_ggplot.pdf 2019-04-23_r_dplyr.pdf 2.3.3 Orderable File names that start with numbers. ISO 8601 standard for dates. left pad other numbers with zero(s). Meaningful names start with numbers allow files to be sorted chronologically. Note that date is in ISO 8601 standard format (YYYY-MM-DD). 2020-01-14_team-meeting-minutes.txt 2020-02-21_team-meeting-minutes.txt 2020-02-22_managers-meeting-minutes.txt 2020-03-16_team-meeting-minutes.txt If date is in other format such as (DD-MM-YYYY), sorting the files does not provide chronological order of events. 14-01-2020_team-meeting-minutes.txt 16-03-2020_team-meeting-minutes.txt 21-02-2020_team-meeting-minutes.txt 22-02-2020_managers-meeting-minutes.txt If files are not meaningful when ordered with date, they can be named with numeric characters first. For instance, a folder of images to be added into another document following a certain sequence. 001_myctophidae_diaphus-adenomus.jpg 002_myctophidae_diaphus-agassizii.jpg ... 010_myctophidae_diaphus-danae.jpg 011_myctophidae_diaphus-fragilis.jpg If the file names are not left pad with zeros, the order will not be chronological as depicted in the example below. 10_myctophidae_diaphus-danae.jpg 1_myctophidae_diaphus-adenomus.jpg 11_myctophidae_diaphus-fragilis.jpg 2_myctophidae_diaphus-agassizii.jpg "],
["tidy-data.html", "Chapter 3 Tidy data 3.1 References", " Chapter 3 Tidy data Tidy data is a standard way of mapping the meaning of a dataset to its structure. Figure from R for Data Science In tidy data: Columns = variables Rows = observations Cells = data (values) 3.1 References https://r4ds.had.co.nz/tidy-data.html https://jhudatascience.org/tidyversecourse/intro.html#tidy-data https://github.com/swcarpentry/good-enough-practices-in-scientific-computing/blob/gh-pages/good-enough-practices-for-scientific-computing.pdf "],
["data-input.html", "Chapter 4 Data input 4.1 Data templates", " Chapter 4 Data input 4.1 Data templates List of biodiversity data templates to record data team can be found in this GitHub repository. Webinar and slides are available at the portal page 4.1.1 Identifiers 4.1.2 Geographical data 4.1.3 Temporal data 4.1.4 Species data 4.1.5 Measurement data "],
["data-quality-control.html", "Chapter 5 Data quality control 5.1 Quality control procedures and tools", " Chapter 5 Data quality control Summary workflow with diagram 5.1 Quality control procedures and tools 5.1.1 Identifiers 5.1.2 Geographical data 5.1.3 Temporal data 5.1.4 Species data 5.1.5 Measurement data "],
["publish-your-biodiversity-data.html", "Chapter 6 Publish your biodiversity data 6.1 Darwin Core archive 6.2 Multimedia files", " Chapter 6 Publish your biodiversity data Types of data and publication methods. 6.1 Darwin Core archive Publish Darwin Core archive with IPT 6.1.1 Dataset metadata (EML) 6.1.2 Core and extension files 6.2 Multimedia files Where to publish your multimedia files? 6.2.1 Specimen images For non-human specimen images, Zenodo is a good option to host your images because: a Digital Object Identifier (DOI) will be assigned to your upload to make it citeable. versioning is supported huge data storage space and much more Publishing with Zenodo Upload If you have plenty of images, uploading one folder containing all of your images for one specific dataset (corresponds to your dataset that will be published via IPT) is the easiest approach. Please ensure that the file names for your images corresponds to your data record in IPT so that the information is properly linked. Communities If your upload is an Antarctic biodiversity dataset, please associate the following communities to your upload: SCAR Scientific Committee on Antarctic Research SCAR Antarctic Biodiversity Portal It helps us to trace what are the datasets uploaded and make your dataset more findable. Basic information Title Please use the same title as your publication in IPT with a suffix -multimedia, e.g.: My title from IPT-multimedia License We recommend Creative Commons Attribution 4.0 International license for the specimen images, where users are free to share and adapt your multimedia but they must give appropriate credit to you, provide a link to the license and indicate if changes were made. "],
["useful-online-resources.html", "Chapter 7 Useful online resources 7.1 Courses and webinars 7.2 Best practices 7.3 Others", " Chapter 7 Useful online resources 7.1 Courses and webinars https://datacarpentry.org/lessons/#ecology-workshop https://www.biodiversity.aq/how-to/webinar-series-biodiversity-data-field-research/ https://inbo.github.io/coding-club/sessions/index.html https://ourcodingclub.github.io/course 7.2 Best practices https://data-blog.gbif.org/ https://obis.org/manual/ https://docs.gbif.org/georeferencing-best-practices/1.0/en/ https://docs.gbif.org/sensitive-species-best-practices/master/en/ https://ioos.github.io/bio_data_guide/intro.html 7.3 Others https://www.gbif.org/resource/search?contentType=tool "]
]
